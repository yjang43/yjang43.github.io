<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>Autoencoders and Transfer Learning</title>

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="stylesheet" href="/assets/css/paginator.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css">
    <!--for kramdown math render-->
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="/">YJ</a>
        <ul class="navbar-nav">
            <li class="nav-item">
                <a class="nav-link py-0" href="/projects/">Projects</a>
            </li>
            <li class="nav-item">
                <a class="nav-link py-0" href="/blog/">Blog</a>
            </li>
        </ul>
    </nav>
    <!-- <div class="jumbotron jumbotron-fluid shadow-lg jumbotron-img">
        <div class="container">
        </div>
    </div> -->

    <div class="container-fluid content-pad">

        <h1>Autoencoders and Transfer Learning</h1>
        <h2 id="autoencoders">Autoencoders</h2>
<p>Autoencoders is an unsupervised learning method to reduce a dimensionality of input.
The main idea is very similar to PCA, but more can be done with autoencoder, for example adding non-linearity or regularization. 
The main idea is to reconstruct an input with limitted features.
Here is a diagram of a simple autoencoder.</p>

<p align="center">
    <img src="/assets/img/autoencoder.png" alt="JVP" width="50%" />
</p>

<p>Basically, the network is composed of encoder and decoder, and lantent features (code) gives a high-level representation of input. 
Some tricks on autoencoder can result in better representation of latent features.
One I will mention is denosing autoencoders invented by Vincet(2008). By masking portion of input, it provides robust representation to partially destructed input, which aligns with the definition author proposed to be a “good” representation. Here is a <strong><a href="https://github.com/yjang43/ml_practice/blob/master/autoencoder.ipynb">link</a></strong> that compares the results of autoencoders and desnoising autoencoder.</p>

<h2 id="transfer-learning-with-autoencoder">Transfer Learning with Autoencoder</h2>
<p>Transfer learning is to use information from source domains, abundant data, to support tasks in target domains, small data.
Glorot(2011) proposes that stacked denoising autoencoder (SDA) can extract intermediate representations from both source and target domain, and use that to help classfication task in target domain.
This idea extends to transfer learning with deep autoencoders (TLDA) by Zhuang (2015), which is a form of supervised learning unlike the usual approach with autoencoder. I have conducted an experiment to check its better performance <strong><a href="https://github.com/yjang43/ml_practice/blob/master/TLDA.ipynb">here</a></strong>.
Instead of using the same dataset from the paper, I used MNIST data.
The task was to check if a binary classfication of a number (ex. is the input ‘1’ when compared with ‘3’) can be transfered to another binary classification (ex. is the input ‘1’ when compared with ‘5’). 
Surprisingly, TLDA performed much better than the baseline, in which I shared parameters trained in simple DNN to another task.
Here is a comparsion of learned feature between TLDA and baseline.
You can see the learned feature from TLDA is more generalized to both the source and target domains.</p>

<p align="center">
    <img src="/assets/img/tlda_result.png" alt="JVP" width="100%" />
</p>


    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
</html>
